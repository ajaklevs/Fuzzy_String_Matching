{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import textdistance\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332470\n"
     ]
    }
   ],
   "source": [
    "amicus = pd.read_csv('csvs/amicus_org_names.csv')['amicus']\n",
    "bonica = pd.read_csv('csvs/bonica_org_names.csv')['x'].unique()\n",
    "print(len(bonica))\n",
    "hand_coded = pd.read_csv('csvs/handcoded.csv')\n",
    "\n",
    "def remove_training_examples(training_set, latest_amicus):\n",
    "    training_terms = set(training_set['amicus'])\n",
    "    return list(set(latest_amicus) - set(training_terms))\n",
    "\n",
    "new_amicus = remove_training_examples(hand_coded, amicus)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('csvs/full_train_set.csv')\n",
    "X_train = train_set[['cosine', 'jaccard', 'levenshtein', 'lcsstr', 'overlap']]\n",
    "y_train = train_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.4s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.4s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.5s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.5s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.5s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.6s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.7s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.6s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.5s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.8s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.1s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.1s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.2s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.3s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.9s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   2.1s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.8s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.9s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   2.1s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.5s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.7s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.3s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'forest__max_depth': 5, 'forest__n_estimators': 10}\n",
      "Feature importances:\n",
      "[0.24418437 0.24320106 0.28538922 0.15744161 0.06978374]\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=10 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=10, total=   0.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.2s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=50 ....................\n",
      "[CV] ..... forest__max_depth=5, forest__n_estimators=50, total=   1.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.5s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.5s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.4s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.3s\n",
      "[CV] forest__max_depth=5, forest__n_estimators=100 ...................\n",
      "[CV] .... forest__max_depth=5, forest__n_estimators=100, total=   2.3s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.7s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.8s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.7s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.7s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=10, forest__n_estimators=50, total=   1.7s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.2s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.4s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.3s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.8s\n",
      "[CV] forest__max_depth=10, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=10, forest__n_estimators=100, total=   3.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=10 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=10, total=   0.4s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.9s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.9s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.7s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   2.0s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=50 ...................\n",
      "[CV] .... forest__max_depth=20, forest__n_estimators=50, total=   1.8s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.7s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.6s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.5s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.7s\n",
      "[CV] forest__max_depth=20, forest__n_estimators=100 ..................\n",
      "[CV] ... forest__max_depth=20, forest__n_estimators=100, total=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'forest__max_depth': 5, 'forest__n_estimators': 100}\n",
      "Feature importances:\n",
      "[0.41063414 0.223605   0.18238633 0.10160645 0.08176807]\n"
     ]
    }
   ],
   "source": [
    "def train(X, y):\n",
    "    #pipeline = Pipeline([('stringdist', stringdist()), ('forest', RandomForestClassifier())])\n",
    "    #rf = RandomForestClassifier()\n",
    "    pipeline = Pipeline([('forest', RandomForestClassifier())])\n",
    "\n",
    "    #the actual model\n",
    "    parameters = {\n",
    "        'forest__max_depth': [5, 10, 20],\n",
    "        'forest__n_estimators': [10, 50, 100]\n",
    "        }\n",
    "\n",
    "    GSCV = GridSearchCV(cv = 5,\n",
    "                       estimator = pipeline,\n",
    "                       param_grid = parameters,\n",
    "                       verbose = 2)\n",
    "\n",
    "    model = GSCV.fit(X, y)\n",
    "\n",
    "    #os.makedirs('partitioned/' + str(it))\n",
    "\n",
    "    print(\"Best parameters:\")\n",
    "    print(model.best_params_)\n",
    "    print(\"Feature importances:\")\n",
    "    print(model.best_estimator_.named_steps[\"forest\"].feature_importances_)\n",
    "\n",
    "    #print(str(model.cv_results_))\n",
    "    #jsond = json.dumps(model.cv_results_)\n",
    "    #f2 = open('partitioned/' + str(it) + '/gridsearch.txt', 'w')\n",
    "    #f2.write(str(model.cv_results_))\n",
    "    #f2.close()\n",
    "\n",
    "    #with open('partitioned/' + str(it) + '/model.pkl', 'wb') as file:\n",
    "    #    pickle.dump(model, file)\n",
    "    #file.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "train_set = pd.read_csv('csvs/full_train_set.csv')\n",
    "X_train = train_set[['cosine', 'jaccard', 'levenshtein', 'lcsstr', 'overlap']]\n",
    "y_train = train_set['label']\n",
    "basic_model = train(X_train, y_train)\n",
    "\n",
    "train_set = pd.read_csv('csvs/iter_6_training_set.csv')\n",
    "X_train = train_set[['cosine', 'jaccard', 'levenshtein', 'lcsstr', 'overlap']]\n",
    "y_train = train_set['label']\n",
    "hitl_model = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>lcsstr</th>\n",
       "      <th>overlap</th>\n",
       "      <th>amicus</th>\n",
       "      <th>bonica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>test1</td>\n",
       "      <td>test4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.358569</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6</td>\n",
       "      <td>test1</td>\n",
       "      <td>something else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>test2</td>\n",
       "      <td>test4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358569</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6</td>\n",
       "      <td>test2</td>\n",
       "      <td>something else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>test3</td>\n",
       "      <td>test4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.358569</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6</td>\n",
       "      <td>test3</td>\n",
       "      <td>something else</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cosine   jaccard  levenshtein  lcsstr  overlap amicus          bonica\n",
       "0  0.800000  0.666667            1       1      0.8  test1           test4\n",
       "1  0.358569  0.187500           12      13      0.6  test1  something else\n",
       "2  0.800000  0.666667            1       1      0.8  test2           test4\n",
       "3  0.358569  0.187500           12      13      0.6  test2  something else\n",
       "4  0.800000  0.666667            1       1      0.8  test3           test4\n",
       "5  0.358569  0.187500           12      13      0.6  test3  something else"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_distances(amicus, bonica):\n",
    "    \n",
    "    cosines = []\n",
    "    lcssts = []\n",
    "    levenshteins = []\n",
    "    jaccards = []\n",
    "    overlaps = []\n",
    "    new_amicus = []\n",
    "    new_bonica = []\n",
    "    \n",
    "    count = 0\n",
    "    for term1 in amicus:\n",
    "        for term2 in bonica:\n",
    "            if count%500000 == 0:\n",
    "                print(count)\n",
    "            count += 1\n",
    "            cosines.append(textdistance.cosine(term1,term2))\n",
    "            lcssts.append(textdistance.lcsstr.distance(term1, term2))\n",
    "            levenshteins.append(textdistance.levenshtein(term1, term2))\n",
    "            jaccards.append(textdistance.jaccard(term1,term2))\n",
    "            overlaps.append(textdistance.overlap(term1,term2))\n",
    "            new_amicus.append(term1)\n",
    "            new_bonica.append(term2)\n",
    "        \n",
    "    return pd.DataFrame({'cosine': cosines, \n",
    "                         'jaccard': jaccards, \n",
    "                         'levenshtein': levenshteins, \n",
    "                         'lcsstr': lcssts, \n",
    "                         'overlap': overlaps,\n",
    "                         'amicus': new_amicus,\n",
    "                         'bonica': new_bonica\n",
    "                        })\n",
    "    \n",
    "    #train_df.to_csv('csvs/current_distances')\n",
    "\n",
    "test_df = calculate_distances(['test1', 'test2', 'test3'], ['test4', 'something else'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "5000000\n",
      "5500000\n",
      "6000000\n",
      "6500000\n",
      "7000000\n",
      "7500000\n",
      "8000000\n",
      "8500000\n",
      "9000000\n",
      "9500000\n",
      "10000000\n"
     ]
    }
   ],
   "source": [
    "hitl_set = pd.read_csv(\"csvs/iter_6_training_set.csv\")\n",
    "new_amicus = remove_training_examples(hitl_set, amicus)\n",
    "\n",
    "bonica_sample = np.random.choice(bonica, size=2000)\n",
    "\n",
    "sample_data = calculate_distances(new_amicus, bonica_sample)\n",
    "\n",
    "sample_data.to_csv('csvs/precomputed_distances_test_set_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american chemistry council' 'american chemistry council']\n",
      "Do these match (y or n): y\n",
      "['united transportation union' 'united transportation union']\n",
      "Do these match (y or n): y\n",
      "['american institute of certified public accountants'\n",
      " 'american institute of certified public accountants']\n",
      "Do these match (y or n): y\n",
      "['wyandotte tribe of oklahoma' 'wyandotte tribe of oklahoma']\n",
      "Do these match (y or n): y\n",
      "['utah school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['american academy of family physicians'\n",
      " 'amer academy of family physicians']\n",
      "Do these match (y or n): y\n",
      "['idaho school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['united auto workers' 'united auto workers v cap']\n",
      "Do these match (y or n): y\n",
      "['american bar association' 'americian beverage association']\n",
      "Do these match (y or n): n\n",
      "['california patent lawyers association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['florida institute of certified public accountants'\n",
      " 'american institute of certified public accountants']\n",
      "Do these match (y or n): y\n",
      "['california apartment association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['ohio school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['virginia trails association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['louisiana school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['minnesota school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['virginia school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['allottees association' 'allen associates']\n",
      "Do these match (y or n): n\n",
      "['arkansas school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['national school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['oregon school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['arab american institute' 'american institute of']\n",
      "Do these match (y or n): n\n",
      "['arizona school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['georgia school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['united steel workers of america afl-cio'\n",
      " 'united steelworkers of america paf']\n",
      "Do these match (y or n): y\n",
      "['mgm/ua communications co' 'yocum communications']\n",
      "Do these match (y or n): n\n",
      "['coalition of mental health professionals'\n",
      " 'wa state coalition of mental health professionals']\n",
      "Do these match (y or n): y\n",
      "['masters communication' 'charter communications']\n",
      "Do these match (y or n): n\n",
      "['united public workers of america' 'united mine workers of america']\n",
      "Do these match (y or n): n\n",
      "[\"california cattlemen's association\" 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['california prosecutors association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['alabama retail association' 'alabama land title association']\n",
      "Do these match (y or n): n\n",
      "['california trustees association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['california forestry association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['american bakers association' 'americian beverage association']\n",
      "Do these match (y or n): n\n",
      "['virginia press association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['tonkawa tribe of oklahoma' 'wyandotte tribe of oklahoma']\n",
      "Do these match (y or n): n\n",
      "['california tax payers association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['american meat institute' 'american institute of']\n",
      "Do these match (y or n): n\n",
      "['california retailers association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['california trial association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['virginia bankers association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['california nurses association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['california state coroners association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['american bankers association' 'americian beverage association']\n",
      "Do these match (y or n): n\n",
      "['american library association' 'americian beverage association']\n",
      "Do these match (y or n): n\n",
      "['alabama education association' 'alabama land title association']\n",
      "Do these match (y or n): n\n",
      "['virginia bankers association' 'virginai beverage association']\n",
      "Do these match (y or n): n\n",
      "['national agricultural aviation association'\n",
      " 'colorado agricultural aviation association']\n",
      "Do these match (y or n): y\n",
      "['west virginia medical association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['amer of texas' 'a shore team']\n",
      "Do these match (y or n): n\n",
      "['pla' 'apollo group']\n",
      "Do these match (y or n): n\n",
      "['amer' 'us postmaster']\n",
      "Do these match (y or n): n\n",
      "['virginia trial lawyers association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['uta' 'auto workers']\n",
      "Do these match (y or n): n\n",
      "['amer' 'a shore team']\n",
      "Do these match (y or n): n\n",
      "['aamr' 'a shore team']\n",
      "Do these match (y or n): n\n",
      "['west virginia coal association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['aamr' 'warfel farms']\n",
      "Do these match (y or n): n\n",
      "['amer' 'warfel farms']\n",
      "Do these match (y or n): n\n",
      "['wes' 'auto workers']\n",
      "Do these match (y or n): n\n",
      "['wes' 'warfel farms']\n",
      "Do these match (y or n): n\n",
      "['american chemical society' 'american chemistry council']\n",
      "Do these match (y or n): n\n",
      "['terr' 'auto workers']\n",
      "Do these match (y or n): n\n",
      "['terr' 'truro demtc']\n",
      "Do these match (y or n): n\n",
      "['dome' 'truro demtc']\n",
      "Do these match (y or n): n\n",
      "['image' 'vigeant cmte']\n",
      "Do these match (y or n): n\n",
      "['camus compact' 'utpac']\n",
      "Do these match (y or n): n\n",
      "['american institute of architects' 'american institute of']\n",
      "Do these match (y or n): n\n",
      "['wildroot co inc' 'tomco oil inc']\n",
      "Do these match (y or n): n\n",
      "['as' 'a shore team']\n",
      "Do these match (y or n): n\n",
      "['as' 'auto workers']\n",
      "Do these match (y or n): n\n",
      "['sas' 'us postmaster']\n",
      "Do these match (y or n): n\n",
      "['as' 'warfel farms']\n",
      "Do these match (y or n): n\n",
      "['uta' 'ben caruth pa']\n",
      "Do these match (y or n): n\n",
      "['as' 'arkla flyers']\n",
      "Do these match (y or n): n\n",
      "['merck and co inc' 'ackerman oil co inc']\n",
      "Do these match (y or n): n\n",
      "['veterans for america' 'cave for senate']\n",
      "Do these match (y or n): n\n",
      "['american rental association' 'asain american retailers association']\n",
      "Do these match (y or n): n\n",
      "['the detroit news' 'the tire network']\n",
      "Do these match (y or n): n\n",
      "['kitsap county' 'utpac']\n",
      "Do these match (y or n): n\n",
      "['uta' 'us postmaster']\n",
      "Do these match (y or n): n\n",
      "['dome' 'the dolan cmte']\n",
      "Do these match (y or n): n\n",
      "['united company' 'utpac']\n",
      "Do these match (y or n): n\n",
      "['california broadcasters association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['pennsylvania school boards association' 'va school boards association']\n",
      "Do these match (y or n): y\n",
      "['cfa institute' 'american institute of']\n",
      "Do these match (y or n): n\n",
      "['washington state hospital association'\n",
      " 'washington state patrol leiutenants association']\n",
      "Do these match (y or n): n\n",
      "['west inc' 'west for council']\n",
      "Do these match (y or n): n\n",
      "['sealaska corp' 'asapac']\n",
      "Do these match (y or n): n\n",
      "['united auto workersuaw' 'auto workers']\n",
      "Do these match (y or n): n\n",
      "['tyler gas service company' 'travelers companies']\n",
      "Do these match (y or n): n\n",
      "['apa watch' 'ahapac']\n",
      "Do these match (y or n): n\n",
      "['mexican student association' 'texas counseling association']\n",
      "Do these match (y or n): n\n",
      "['gulf oil corporation' 'all pro roofing']\n",
      "Do these match (y or n): n\n",
      "['virginia sheriffs association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['virginia forestry association' 'virginia retail association']\n",
      "Do these match (y or n): n\n",
      "['american diabetes association' 'americian beverage association']\n",
      "Do these match (y or n): n\n",
      "['cargo airline association' 'california parents association']\n",
      "Do these match (y or n): n\n",
      "['ameri' 'bp north america']\n",
      "Do these match (y or n): n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajaklevs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "distances_path = 'csvs/precomputed_distances_iter5.csv'\n",
    "model = model_iter_5\n",
    "current_amicus = new_amicus\n",
    "\n",
    "def ask_about_matches(match_pairs):\n",
    "    matches = []\n",
    "    for pair in match_pairs:\n",
    "        match = ''\n",
    "        while match != 'y' and match != 'n':\n",
    "            print(pair)\n",
    "            match = input(\"Do these match (y or n): \")\n",
    "\n",
    "        if match == 'y':\n",
    "            matches.append(1)\n",
    "        elif match == 'n':\n",
    "            matches.append(0)\n",
    "\n",
    "    return matches\n",
    "\n",
    "def complete_iteration(distances_path, model, current_amicus):\n",
    "    iter_df = pd.read_csv(distances_path)\n",
    "    X = iter_df[['cosine', 'jaccard', 'levenshtein', 'lcsstr', 'overlap']]\n",
    "    iter_df['score'] = model.predict_proba(X)[:,1]\n",
    "    iter_df = iter_df.sort_values('score', ascending=False)\n",
    "    \n",
    "    best_matches = iter_df.head(100)\n",
    "    \n",
    "    pairs = np.array(best_matches[['amicus', 'bonica']])\n",
    "    \n",
    "    answers = ask_about_matches(pairs)\n",
    "    \n",
    "    best_matches['label'] = answers\n",
    "    \n",
    "    return best_matches\n",
    "    \n",
    "    \n",
    "new_training_set = complete_iteration(distances_path, model, current_amicus)\n",
    "new_amicus = remove_training_examples(new_training_set, current_amicus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajaklevs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "iter_6_training_set = pd.concat([iter_5_training_set,new_training_set], axis=0)\n",
    "\n",
    "iter_6_training_set.to_csv('csvs/iter_6_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cosine</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>lcsstr</th>\n",
       "      <th>overlap</th>\n",
       "      <th>amicus</th>\n",
       "      <th>bonica</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4811684</th>\n",
       "      <td>4811684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>republicans for choice</td>\n",
       "      <td>republicans for choice</td>\n",
       "      <td>0.991889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439039</th>\n",
       "      <td>5439039</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>global marine inc</td>\n",
       "      <td>le blanc, marion</td>\n",
       "      <td>0.342382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450921</th>\n",
       "      <td>4450921</td>\n",
       "      <td>0.898717</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>eastern air lines inc</td>\n",
       "      <td>united americans in israel</td>\n",
       "      <td>0.302284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244846</th>\n",
       "      <td>1244846</td>\n",
       "      <td>0.887625</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>american iron and steel institute</td>\n",
       "      <td>united americans in israel</td>\n",
       "      <td>0.213792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884795</th>\n",
       "      <td>5884795</td>\n",
       "      <td>0.858395</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>olan mills inc</td>\n",
       "      <td>mcwilliams od, lynn</td>\n",
       "      <td>0.192231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658755</th>\n",
       "      <td>4658755</td>\n",
       "      <td>0.821995</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>charter one financial inc</td>\n",
       "      <td>north carolina election campaign fund</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585831</th>\n",
       "      <td>6585831</td>\n",
       "      <td>0.877733</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>national federation of independent business of...</td>\n",
       "      <td>national federation of independent business nf...</td>\n",
       "      <td>0.099430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111764</th>\n",
       "      <td>4111764</td>\n",
       "      <td>0.771517</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>american littoral society</td>\n",
       "      <td>california congressional victory committee</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459735</th>\n",
       "      <td>5459735</td>\n",
       "      <td>0.771100</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>asthma and allergy foundation careinc</td>\n",
       "      <td>lynn martin for senate</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739632</th>\n",
       "      <td>2739632</td>\n",
       "      <td>0.771100</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>coalitions for america</td>\n",
       "      <td>coalition for asian pacific americans</td>\n",
       "      <td>0.098946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0    cosine   jaccard  levenshtein  lcsstr   overlap  \\\n",
       "4811684     4811684  1.000000  1.000000            0       0  1.000000   \n",
       "5439039     5439039  0.909509  0.833333           12      12  0.937500   \n",
       "4450921     4450921  0.898717  0.807692           18      22  1.000000   \n",
       "1244846     1244846  0.887625  0.787879           25      25  1.000000   \n",
       "5884795     5884795  0.858395  0.736842           15      16  1.000000   \n",
       "...             ...       ...       ...          ...     ...       ...   \n",
       "4658755     4658755  0.821995  0.675676           26      34  1.000000   \n",
       "6585831     6585831  0.877733  0.781250           13      15  0.909091   \n",
       "4111764     4111764  0.771517  0.595238           29      39  1.000000   \n",
       "5459735     5459735  0.771100  0.594595           29      34  1.000000   \n",
       "2739632     2739632  0.771100  0.594595           17      28  1.000000   \n",
       "\n",
       "                                                    amicus  \\\n",
       "4811684                             republicans for choice   \n",
       "5439039                                  global marine inc   \n",
       "4450921                              eastern air lines inc   \n",
       "1244846                  american iron and steel institute   \n",
       "5884795                                     olan mills inc   \n",
       "...                                                    ...   \n",
       "4658755                          charter one financial inc   \n",
       "6585831  national federation of independent business of...   \n",
       "4111764                          american littoral society   \n",
       "5459735              asthma and allergy foundation careinc   \n",
       "2739632                             coalitions for america   \n",
       "\n",
       "                                                    bonica     score  label  \n",
       "4811684                             republicans for choice  0.991889      1  \n",
       "5439039                                   le blanc, marion  0.342382      0  \n",
       "4450921                         united americans in israel  0.302284      0  \n",
       "1244846                         united americans in israel  0.213792      0  \n",
       "5884795                                mcwilliams od, lynn  0.192231      0  \n",
       "...                                                    ...       ...    ...  \n",
       "4658755              north carolina election campaign fund  0.100409      0  \n",
       "6585831  national federation of independent business nf...  0.099430      1  \n",
       "4111764         california congressional victory committee  0.099094      0  \n",
       "5459735                             lynn martin for senate  0.099094      0  \n",
       "2739632              coalition for asian pacific americans  0.098946      0  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting hitl predictions\n",
      "finished hitl score\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.read_csv('csvs/precomputed_distances_test_set.csv')\n",
    "X = test_set[['cosine', 'jaccard', 'levenshtein', 'lcsstr', 'overlap']]\n",
    "print('getting hitl predictions')\n",
    "test_set['hitl_score'] = hitl_model.predict_proba(X)[:,1]\n",
    "print('finished hitl score')\n",
    "test_set['score'] = basic_model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#test_set = test_set.sort_values('score', ascending=False)\n",
    "test_set = test_set.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set.head(5000).to_csv('csvs/final_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(1*(test_set['score'] >= .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
